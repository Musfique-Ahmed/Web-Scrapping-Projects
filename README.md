# 🕸️ Web Scraping Portfolio with Python

Welcome to my Web Scraping Portfolio! 👨‍💻  
This repository contains a collection of hands-on Python projects where I extract, clean, and store data from websites and APIs using tools like **BeautifulSoup**, **Selenium**, **Scrapy**, and **Pandas**.

Whether you're looking for static site scraping, handling dynamic content, or structured API data extraction — this portfolio demonstrates my ability to build clean, modular, and scalable scrapers.

---

## 🛠️ Technologies & Tools Used
- **Languages:** Python 3.x  
- **Libraries/Frameworks:** BeautifulSoup, Selenium, Scrapy, Pandas, Requests  
- **Databases:** MySQL, PostgreSQL  
- **Output Formats:** CSV, JSON  
- **Utilities:** Git, Logging, Exception Handling

---

## 📁 Project List

| Project | Description | Tools Used |
|--------|-------------|-------------|
| `amazon_price_tracker` | Tracks the price of products from Amazon and logs them in CSV. | BeautifulSoup, Requests |
| `job_site_dynamic_scraper` | Scrapes job listings from dynamic content sites using browser automation. | Selenium |
| `real_estate_scraper` | Collects real estate listing data including images and prices. | Selenium, Pandas |
| `api_data_collector` | Pulls structured data from a public REST API and stores it in JSON/SQL. | Requests, JSON, PostgreSQL |
| More coming soon... | Stay tuned for additional case studies and tools. | 🔄 |

---

## 📌 How to Use
1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/web-scraping-portfolio
   cd web-scraping-portfolio
