# ğŸ•¸ï¸ Web Scraping Portfolio with Python

Welcome to my Web Scraping Portfolio! ğŸ‘¨â€ğŸ’»  
This repository contains a collection of hands-on Python projects where I extract, clean, and store data from websites and APIs using tools like **BeautifulSoup**, **Selenium**, **Scrapy**, and **Pandas**.

Whether you're looking for static site scraping, handling dynamic content, or structured API data extraction â€” this portfolio demonstrates my ability to build clean, modular, and scalable scrapers.

---

## ğŸ› ï¸ Technologies & Tools Used
- **Languages:** Python 3.x  
- **Libraries/Frameworks:** BeautifulSoup, Selenium, Scrapy, Pandas, Requests  
- **Databases:** MySQL, PostgreSQL  
- **Output Formats:** CSV, JSON  
- **Utilities:** Git, Logging, Exception Handling

---

## ğŸ“ Project List

| Project | Description | Tools Used |
|--------|-------------|-------------|
| `amazon_price_tracker` | Tracks the price of products from Amazon and logs them in CSV. | BeautifulSoup, Requests |
| `job_site_dynamic_scraper` | Scrapes job listings from dynamic content sites using browser automation. | Selenium |
| `real_estate_scraper` | Collects real estate listing data including images and prices. | Selenium, Pandas |
| `api_data_collector` | Pulls structured data from a public REST API and stores it in JSON/SQL. | Requests, JSON, PostgreSQL |
| More coming soon... | Stay tuned for additional case studies and tools. | ğŸ”„ |

---

## ğŸ“Œ How to Use
1. Clone the repo:
   ```bash
   git clone https://github.com/yourusername/web-scraping-portfolio
   cd web-scraping-portfolio
